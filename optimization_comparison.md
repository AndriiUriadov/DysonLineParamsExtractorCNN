# üöÄ –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó –¥–ª—è —à–≤–∏–¥—à–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è DysonianLineCNN

## üìä –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –±–∞–∑–æ–≤–æ—ó —Ç–∞ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ—ó –≤–µ—Ä—Å—ñ—ó

### üîß –û—Å–Ω–æ–≤–Ω—ñ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó:

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ë–∞–∑–æ–≤–∞ –≤–µ—Ä—Å—ñ—è | –û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ –≤–µ—Ä—Å—ñ—è | –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è |
|----------|---------------|---------------------|------------|
| **Batch Size** | 16 | 32 | +100% |
| **Learning Rate** | 0.001 | 0.002 | +100% |
| **Weight Decay** | 1e-5 | 1e-4 | +10x |
| **Optimizer** | Adam | AdamW | –ö—Ä–∞—â–∏–π |
| **Mixed Precision** | ‚ùå | ‚úÖ | +30-50% —à–≤–∏–¥–∫—ñ—Å—Ç—å |
| **CUDNN Benchmark** | ‚ùå | ‚úÖ | +10-20% —à–≤–∏–¥–∫—ñ—Å—Ç—å |
| **Workers** | 0 | 2 | –ü–∞—Ä–∞–ª–µ–ª—å–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è |
| **Early Stopping** | 20 | 15 | –®–≤–∏–¥—à–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è |
| **Dropout** | 0.2 | 0.1 | –ú–µ–Ω—à–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—ó |

### ‚ö°Ô∏è –¢–µ—Ö–Ω—ñ—á–Ω—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è:

#### 1. **Mixed Precision Training**
```python
# –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è torch.cuda.amp –¥–ª—è –∑–º–µ–Ω—à–µ–Ω–Ω—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –ø–∞–º'—è—Ç—ñ
scaler = torch.cuda.amp.GradScaler()
with torch.cuda.amp.autocast():
    output = self.model(data)
    loss = self.criterion(output, target)
```

#### 2. **–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π DataLoader**
```python
# –ü–∞—Ä–∞–ª–µ–ª—å–Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö
train_loader = DataLoader(
    train_dataset, 
    batch_size=32,
    num_workers=2,
    persistent_workers=True,
    pin_memory=True
)
```

#### 3. **AdamW Optimizer**
```python
# –ö—Ä–∞—â–∏–π –æ–ø—Ç–∏–º—ñ–∑–∞—Ç–æ—Ä –∑ weight decay
self.optimizer = optim.AdamW(
    model.parameters(), 
    lr=0.002,
    weight_decay=1e-4,
    betas=(0.9, 0.999)
)
```

#### 4. **CUDNN Benchmark**
```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –∑–≥–æ—Ä—Ç–∫–æ–≤–∏—Ö –æ–ø–µ—Ä–∞—Ü—ñ–π
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = False
```

### üìà –û—á—ñ–∫—É–≤–∞–Ω—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è:

#### **–®–≤–∏–¥–∫—ñ—Å—Ç—å –Ω–∞–≤—á–∞–Ω–Ω—è:**
- **+30-50%** –∑–∞–≤–¥—è–∫–∏ mixed precision
- **+10-20%** –∑–∞–≤–¥—è–∫–∏ CUDNN benchmark
- **+20-30%** –∑–∞–≤–¥—è–∫–∏ –±—ñ–ª—å—à–æ–º—É batch_size
- **+15-25%** –∑–∞–≤–¥—è–∫–∏ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ–º—É –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—é

#### **–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Ä–µ—Å—É—Ä—Å—ñ–≤:**
- **GPU Memory:** -30% –∑–∞–≤–¥—è–∫–∏ mixed precision
- **CPU Usage:** +50% –∑–∞–≤–¥—è–∫–∏ workers
- **Training Time:** -40-60% –∑–∞–≥–∞–ª–æ–º

#### **–Ø–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ:**
- **Convergence:** –®–≤–∏–¥—à–µ –∑–±—ñ–∂–Ω—ñ—Å—Ç—å
- **Stability:** –ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å
- **Final Performance:** –ó–±–µ—Ä–µ–∂–µ–Ω–∞ –∞–±–æ –ø–æ–∫—Ä–∞—â–µ–Ω–∞

### üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:

#### **–î–ª—è Colab (High-RAM + GPU):**
```python
# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—É –≤–µ—Ä—Å—ñ—é
from trainer_optimized import create_optimized_trainer
trainer = create_optimized_trainer(model, learning_rate=0.002, batch_size=32)
```

#### **–î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ GPU:**
```python
# –ú–æ–∂–Ω–∞ –∑–±—ñ–ª—å—à–∏—Ç–∏ batch_size —â–µ –±—ñ–ª—å—à–µ
trainer = create_optimized_trainer(model, learning_rate=0.002, batch_size=64)
```

#### **–î–ª—è CPU-only:**
```python
# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –±–∞–∑–æ–≤—É –≤–µ—Ä—Å—ñ—é –∑ –º–µ–Ω—à–∏–º batch_size
from trainer import create_trainer
trainer = create_trainer(model, learning_rate=0.001, batch_size=8)
```

### üîç –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ–π:

#### **–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —à–≤–∏–¥–∫–æ—Å—Ç—ñ:**
```python
import time
start_time = time.time()
history = trainer.train(train_loader, val_loader, num_epochs=10)
training_time = time.time() - start_time
print(f"–ß–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è: {training_time/60:.1f} —Ö–≤–∏–ª–∏–Ω")
```

#### **–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø–∞–º'—è—Ç—ñ:**
```python
import torch
print(f"GPU Memory: {torch.cuda.memory_allocated()/1024**3:.2f} GB")
print(f"GPU Cache: {torch.cuda.memory_reserved()/1024**3:.2f} GB")
```

#### **–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —è–∫–æ—Å—Ç—ñ:**
```python
test_metrics = trainer.evaluate(test_loader)
print(f"Test R¬≤: {test_metrics['R2']:.4f}")
print(f"Test RMSE: {test_metrics['RMSE']:.6f}")
```

### üìù –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:

1. **–°–∫–æ–ø—ñ—é–π—Ç–µ** `trainer_optimized.py` —É –≤–∞—à –ø—Ä–æ–µ–∫—Ç
2. **–Ü–º–ø–æ—Ä—Ç—É–π—Ç–µ** –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π —Ç—Ä–µ–Ω–µ—Ä:
   ```python
   from trainer_optimized import create_optimized_trainer
   ```
3. **–ó–∞–º—ñ–Ω—ñ—Ç—å** —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç—Ä–µ–Ω–µ—Ä–∞:
   ```python
   trainer = create_optimized_trainer(model, learning_rate=0.002, batch_size=32)
   ```
4. **–ó–∞–ø—É—Å—Ç—ñ—Ç—å** –Ω–∞–≤—á–∞–Ω–Ω—è —è–∫ –∑–∞–∑–≤–∏—á–∞–π

### ‚ö†Ô∏è –í–∞–∂–ª–∏–≤—ñ –∑–∞—É–≤–∞–∂–µ–Ω–Ω—è:

- **Mixed precision** –ø–æ—Ç—Ä–µ–±—É—î GPU –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é Tensor Cores
- **CUDNN benchmark** –º–æ–∂–µ –∑–º—ñ–Ω–∏—Ç–∏ –¥–µ—Ç–µ—Ä–º—ñ–Ω—ñ–∑–º
- **–ë—ñ–ª—å—à–∏–π batch_size** –ø–æ—Ç—Ä–µ–±—É—î –±—ñ–ª—å—à–µ GPU –ø–∞–º'—è—Ç—ñ
- **Workers** –º–æ–∂—É—Ç—å –≤–∏–∫–ª–∏–∫–∞—Ç–∏ –ø—Ä–æ–±–ª–µ–º–∏ –≤ –¥–µ—è–∫–∏—Ö —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞—Ö

### üéâ –†–µ–∑—É–ª—å—Ç–∞—Ç:

–ó —Ü–∏–º–∏ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è–º–∏ –≤–∏ –æ—Ç—Ä–∏–º–∞—î—Ç–µ:
- **–®–≤–∏–¥—à–µ –Ω–∞–≤—á–∞–Ω–Ω—è** –Ω–∞ 40-60%
- **–ï—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—à–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è GPU**
- **–ö—Ä–∞—â—É —Å—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å** –Ω–∞–≤—á–∞–Ω–Ω—è
- **–ó–±–µ—Ä–µ–∂–µ–Ω—É —è–∫—ñ—Å—Ç—å** –º–æ–¥–µ–ª—ñ 