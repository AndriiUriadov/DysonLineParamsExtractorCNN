# =============================================================================
# –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –¢–ê –ü–Ü–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ò–•
# =============================================================================

import gdown
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

def download_data():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –¥–∞–Ω—ñ –∑ Google Drive
    Returns:
        tuple: (X, y) - –≤—Ö—ñ–¥–Ω—ñ —Ç–∞ –≤–∏—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ
    """
    print("üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö...")
    
    # Google Drive file IDs
    file_id_X = '1kOeVd4d1PZfPhfoVIPKXSUScV0tfiRcD'
    file_id_y = '1LKHYyAnb3Ls1qKbxlXOvc6mUY_fMSiAk'

    # –°—Ç–≤–æ—Ä—é—î–º–æ –ø—Ä—è–º—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è
    url_X = f'https://drive.google.com/uc?id={file_id_X}'
    url_y = f'https://drive.google.com/uc?id={file_id_y}'

    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ñ–∞–π–ª–∏
    gdown.download(url_X, 'X_dyson.npy', quiet=False)
    gdown.download(url_y, 'y_dyson.npy', quiet=False)

    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —É –∑–º—ñ–Ω–Ω—ñ
    X = np.load('X_dyson.npy')
    y = np.load('y_dyson.npy')

    print("‚úÖ –î–∞–Ω—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ!")
    print(f"   X.shape = {X.shape}")
    print(f"   y.shape = {y.shape}")
    
    return X, y

def preprocess_data(X, y):
    """
    –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è
    Args:
        X: –≤—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ
        y: –≤–∏—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ
    Returns:
        tuple: (X_train, X_val, X_test, y_train, y_val, y_test, scaler_y, y_min, y_max)
    """
    print("üîß –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö...")
    
    # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö X (—Å–µ—Ä–µ–¥–Ω—î 0, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è 1)
    X_mean = np.mean(X, axis=1, keepdims=True)
    X_std = np.std(X, axis=1, keepdims=True)
    X_normalized = (X - X_mean) / X_std

    # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –≤–∏—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö y (–º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –¥–æ [0,1])
    scaler_y = MinMaxScaler()
    y_normalized = scaler_y.fit_transform(y)

    # –ó–±–µ—Ä–µ–∂–µ–º–æ —Ç–∞–∫–æ–∂ –º–∞–∫—Å–∏–º—É–º–∏ —ñ –º—ñ–Ω—ñ–º—É–º–∏ y –¥–ª—è –ø–æ–¥–∞–ª—å—à–æ–≥–æ –¥–µ–Ω–æ—Ä–º—É–≤–∞–Ω–Ω—è
    y_min = scaler_y.data_min_
    y_max = scaler_y.data_max_

    print("   –ú—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è y:", y_min)
    print("   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è y:", y_max)

    # –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ train/val/test
    X_train, X_temp, y_train, y_temp = train_test_split(X_normalized, y_normalized, test_size=0.3, random_state=42)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

    print("‚úÖ –î–∞–Ω—ñ –ø—ñ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ!")
    print(f"   Train set: {X_train.shape}, {y_train.shape}")
    print(f"   Validation set: {X_val.shape}, {y_val.shape}")
    print(f"   Test set: {X_test.shape}, {y_test.shape}")
    print(f"   Min y: {np.min(y_train, axis=0)}")  # –º–∞—î –±—É—Ç–∏ ~0
    print(f"   Max y: {np.max(y_train, axis=0)}")  # –º–∞—î –±—É—Ç–∏ ~1

    return X_train, X_val, X_test, y_train, y_val, y_test, scaler_y, y_min, y_max

def visualize_random_spectra(X_train, X_val, X_test, y_train, y_val, y_test, X_original=None):
    """
    –í—ñ–∑—É–∞–ª—ñ–∑—É—î 2 –≤–∏–ø–∞–¥–∫–æ–≤–∏—Ö —Å–ø–µ–∫—Ç—Ä–∏ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—é –ø—Ä–æ—Ü–µ—Å—ñ–≤ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó
    
    Args:
        X_train, X_val, X_test: –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –≤—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ
        y_train, y_val, y_test: –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –≤–∏—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ
        X_original: –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
    """
    import matplotlib.pyplot as plt
    import random
    
    print("üìä –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –≤–∏–ø–∞–¥–∫–æ–≤–∏—Ö —Å–ø–µ–∫—Ç—Ä—ñ–≤ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—é...")
    
    # –í–∏–±—ñ—Ä –≤–∏–ø–∞–¥–∫–æ–≤–∏—Ö —ñ–Ω–¥–µ–∫—Å—ñ–≤
    train_idx = random.randint(0, len(X_train) - 1)
    val_idx = random.randint(0, len(X_val) - 1)
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –≥—Ä–∞—Ñ—ñ–∫
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # –°–ø–µ–∫—Ç—Ä 1: Train set
    axes[0, 0].plot(X_train[train_idx], 'b-', linewidth=1, alpha=0.8)
    axes[0, 0].set_title(f'Train Spectrum #{train_idx}', fontsize=12, fontweight='bold')
    axes[0, 0].set_xlabel('Frequency Channel')
    axes[0, 0].set_ylabel('Normalized Intensity')
    axes[0, 0].grid(True, alpha=0.3)
    axes[0, 0].text(0.02, 0.98, f'Parameters: B0={y_train[train_idx, 0]:.3f}, dB={y_train[train_idx, 1]:.3f}\np={y_train[train_idx, 2]:.3f}, I={y_train[train_idx, 3]:.3f}', 
                     transform=axes[0, 0].transAxes, verticalalignment='top', 
                     bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    # –°–ø–µ–∫—Ç—Ä 2: Validation set
    axes[0, 1].plot(X_val[val_idx], 'r-', linewidth=1, alpha=0.8)
    axes[0, 1].set_title(f'Validation Spectrum #{val_idx}', fontsize=12, fontweight='bold')
    axes[0, 1].set_xlabel('Frequency Channel')
    axes[0, 1].set_ylabel('Normalized Intensity')
    axes[0, 1].grid(True, alpha=0.3)
    axes[0, 1].text(0.02, 0.98, f'Parameters: B0={y_val[val_idx, 0]:.3f}, dB={y_val[val_idx, 1]:.3f}\np={y_val[val_idx, 2]:.3f}, I={y_val[val_idx, 3]:.3f}', 
                     transform=axes[0, 1].transAxes, verticalalignment='top', 
                     bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8))
    
    # –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–æ–≥–æ (—è–∫—â–æ —î –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ)
    if X_original is not None:
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ —ñ–Ω–¥–µ–∫—Å–∏ –≤ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö
        original_train_idx = train_idx  # –ü—Ä–∏–±–ª–∏–∑–Ω–æ
        original_val_idx = len(X_original) - len(X_test) - len(X_val) + val_idx
        
        axes[1, 0].plot(X_original[original_train_idx], 'g-', linewidth=1, alpha=0.6, label='Original')
        axes[1, 0].plot(X_train[train_idx], 'b-', linewidth=1, alpha=0.8, label='Normalized')
        axes[1, 0].set_title('Train: Original vs Normalized', fontsize=12, fontweight='bold')
        axes[1, 0].set_xlabel('Frequency Channel')
        axes[1, 0].set_ylabel('Intensity')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        axes[1, 1].plot(X_original[original_val_idx], 'g-', linewidth=1, alpha=0.6, label='Original')
        axes[1, 1].plot(X_val[val_idx], 'r-', linewidth=1, alpha=0.8, label='Normalized')
        axes[1, 1].set_title('Validation: Original vs Normalized', fontsize=12, fontweight='bold')
        axes[1, 1].set_xlabel('Frequency Channel')
        axes[1, 1].set_ylabel('Intensity')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
    else:
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó
        axes[1, 0].hist(X_train.flatten(), bins=50, alpha=0.7, color='blue', label='Train')
        axes[1, 0].hist(X_val.flatten(), bins=50, alpha=0.7, color='red', label='Validation')
        axes[1, 0].set_title('Distribution of Normalized Values', fontsize=12, fontweight='bold')
        axes[1, 0].set_xlabel('Normalized Intensity')
        axes[1, 0].set_ylabel('Frequency')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
        param_names = ['B0', 'dB', 'p', 'I']
        train_means = [np.mean(y_train[:, i]) for i in range(4)]
        val_means = [np.mean(y_val[:, i]) for i in range(4)]
        
        x_pos = np.arange(len(param_names))
        width = 0.35
        
        axes[1, 1].bar(x_pos - width/2, train_means, width, label='Train', alpha=0.7, color='blue')
        axes[1, 1].bar(x_pos + width/2, val_means, width, label='Validation', alpha=0.7, color='red')
        axes[1, 1].set_title('Mean Parameter Values', fontsize=12, fontweight='bold')
        axes[1, 1].set_xlabel('Parameters')
        axes[1, 1].set_ylabel('Normalized Value')
        axes[1, 1].set_xticks(x_pos)
        axes[1, 1].set_xticklabels(param_names)
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # –í–∏–≤–æ–¥–∏–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print(f"üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó:")
    print(f"   Train X - Mean: {np.mean(X_train):.6f}, Std: {np.std(X_train):.6f}")
    print(f"   Val X - Mean: {np.mean(X_val):.6f}, Std: {np.std(X_val):.6f}")
    print(f"   Train y - Min: {np.min(y_train, axis=0)}, Max: {np.max(y_train, axis=0)}")
    print(f"   Val y - Min: {np.min(y_val, axis=0)}, Max: {np.max(y_val, axis=0)}")
    print(f"‚úÖ –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

def create_data_dict(y_train, y_val, y_test):
    """
    –°—Ç–≤–æ—Ä—é—î —Å–ª–æ–≤–Ω–∏–∫–∏ –∑ –¥–∞–Ω–∏–º–∏ –¥–ª—è –∑—Ä—É—á–Ω–æ—Å—Ç—ñ
    Args:
        y_train, y_val, y_test: –≤–∏—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ
    Returns:
        tuple: (y_train_dict, y_val_dict, y_test_dict)
    """
    y_train_dict = {
        'B0': y_train[:, 0],
        'dB': y_train[:, 1],
        'p':  y_train[:, 2],
        'I':  y_train[:, 3]
    }
    
    y_val_dict = {
        'B0': y_val[:, 0],
        'dB': y_val[:, 1],
        'p':  y_val[:, 2],
        'I':  y_val[:, 3]
    }
    
    y_test_dict = {
        'B0': y_test[:, 0],
        'dB': y_test[:, 1],
        'p':  y_test[:, 2],
        'I':  y_test[:, 3]
    }
    
    return y_train_dict, y_val_dict, y_test_dict

def load_and_preprocess():
    """
    –ü–æ–≤–Ω–∏–π –ø—Ä–æ—Ü–µ—Å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–∏—Ö
    Returns:
        tuple: –≤—Å—ñ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è
    """
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ
    X, y = download_data()
    
    # –ü—ñ–¥–≥–æ—Ç–æ–≤–ª—è—î–º–æ –¥–∞–Ω—ñ
    X_train, X_val, X_test, y_train, y_val, y_test, scaler_y, y_min, y_max = preprocess_data(X, y)
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–ª–æ–≤–Ω–∏–∫–∏
    y_train_dict, y_val_dict, y_test_dict = create_data_dict(y_train, y_val, y_test)
    
    # –í—ñ–∑—É–∞–ª—ñ–∑—É—î–º–æ –≤–∏–ø–∞–¥–∫–æ–≤—ñ —Å–ø–µ–∫—Ç—Ä–∏ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—é
    visualize_random_spectra(X_train, X_val, X_test, y_train, y_val, y_test, X_original=X)
    
    return (X_train, X_val, X_test, y_train, y_val, y_test, 
            y_train_dict, y_val_dict, y_test_dict, scaler_y, y_min, y_max) 