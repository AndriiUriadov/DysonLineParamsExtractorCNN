# =============================================================================
# –î–û–ü–û–ú–Ü–ñ–ù–Ü –§–£–ù–ö–¶–Ü–á
# =============================================================================

import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import pickle
import os

def denormalize_predictions(predictions, scaler_y):
    """
    –î–µ–Ω–æ—Ä–º–∞–ª—ñ–∑—É—î –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
    
    Args:
        predictions: –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
        scaler_y: scaler, —è–∫–∏–π –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–≤—Å—è –¥–ª—è –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó
    
    Returns:
        denormalized: –¥–µ–Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
    """
    return scaler_y.inverse_transform(predictions)

def normalize_predictions(predictions, scaler_y):
    """
    –ù–æ—Ä–º–∞–ª—ñ–∑—É—î –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
    
    Args:
        predictions: –¥–µ–Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
        scaler_y: scaler, —è–∫–∏–π –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–≤—Å—è –¥–ª—è –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó
    
    Returns:
        normalized: –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
    """
    return scaler_y.transform(predictions)

def calculate_detailed_metrics(predictions, targets, param_names=['B0', 'dB', 'p', 'I']):
    """
    –û–±—á–∏—Å–ª—é—î –¥–µ—Ç–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
    
    Args:
        predictions: –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
        targets: —Å–ø—Ä–∞–≤–∂–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        param_names: –Ω–∞–∑–≤–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    
    Returns:
        dict: –¥–µ—Ç–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏
    """
    metrics = {}
    
    # –ó–∞–≥–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏
    metrics['overall'] = {
        'MSE': mean_squared_error(targets, predictions),
        'RMSE': np.sqrt(mean_squared_error(targets, predictions)),
        'MAE': mean_absolute_error(targets, predictions),
        'R2': r2_score(targets, predictions)
    }
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
    for i, param in enumerate(param_names):
        param_pred = predictions[:, i]
        param_target = targets[:, i]
        
        metrics[param] = {
            'MSE': mean_squared_error(param_target, param_pred),
            'RMSE': np.sqrt(mean_squared_error(param_target, param_pred)),
            'MAE': mean_absolute_error(param_target, param_pred),
            'R2': r2_score(param_target, param_pred),
            'Mean': np.mean(param_pred),
            'Std': np.std(param_pred),
            'Min': np.min(param_pred),
            'Max': np.max(param_pred)
        }
    
    return metrics

def plot_predictions_vs_targets(predictions, targets, param_names=['B0', 'dB', 'p', 'I'], 
                               figsize=(15, 10)):
    """
    –í—ñ–∑—É–∞–ª—ñ–∑—É—î –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –ø—Ä–æ—Ç–∏ —Å–ø—Ä–∞–≤–∂–Ω—ñ—Ö –∑–Ω–∞—á–µ–Ω—å
    
    Args:
        predictions: –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
        targets: —Å–ø—Ä–∞–≤–∂–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        param_names: –Ω–∞–∑–≤–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
        figsize: —Ä–æ–∑–º—ñ—Ä –≥—Ä–∞—Ñ—ñ–∫–∞
    """
    fig, axes = plt.subplots(2, 2, figsize=figsize)
    axes = axes.flatten()
    
    for i, param in enumerate(param_names):
        ax = axes[i]
        
        # Scatter plot
        ax.scatter(targets[:, i], predictions[:, i], alpha=0.6, s=20)
        
        # Perfect prediction line
        min_val = min(targets[:, i].min(), predictions[:, i].min())
        max_val = max(targets[:, i].max(), predictions[:, i].max())
        ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)
        
        # Calculate R¬≤
        r2 = r2_score(targets[:, i], predictions[:, i])
        rmse = np.sqrt(mean_squared_error(targets[:, i], predictions[:, i]))
        
        ax.set_xlabel(f'True {param}')
        ax.set_ylabel(f'Predicted {param}')
        ax.set_title(f'{param}: R¬≤ = {r2:.4f}, RMSE = {rmse:.4f}')
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

def plot_residuals(predictions, targets, param_names=['B0', 'dB', 'p', 'I'], 
                   figsize=(15, 10)):
    """
    –í—ñ–∑—É–∞–ª—ñ–∑—É—î –∑–∞–ª–∏—à–∫–∏ (residuals) –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
    
    Args:
        predictions: –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
        targets: —Å–ø—Ä–∞–≤–∂–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        param_names: –Ω–∞–∑–≤–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
        figsize: —Ä–æ–∑–º—ñ—Ä –≥—Ä–∞—Ñ—ñ–∫–∞
    """
    fig, axes = plt.subplots(2, 2, figsize=figsize)
    axes = axes.flatten()
    
    for i, param in enumerate(param_names):
        ax = axes[i]
        
        residuals = predictions[:, i] - targets[:, i]
        
        # Histogram of residuals
        ax.hist(residuals, bins=30, alpha=0.7, edgecolor='black')
        ax.axvline(x=0, color='red', linestyle='--', linewidth=2)
        
        ax.set_xlabel(f'Residuals {param}')
        ax.set_ylabel('Frequency')
        ax.set_title(f'Residuals Distribution: {param}')
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

def plot_training_curves(train_losses, val_losses, train_metrics, val_metrics, 
                        figsize=(15, 10)):
    """
    –í—ñ–∑—É–∞–ª—ñ–∑—É—î –∫—Ä–∏–≤—ñ –Ω–∞–≤—á–∞–Ω–Ω—è
    
    Args:
        train_losses: –≤—Ç—Ä–∞—Ç–∏ –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—ñ
        val_losses: –≤—Ç—Ä–∞—Ç–∏ –Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
        train_metrics: –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—ñ
        val_metrics: –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
        figsize: —Ä–æ–∑–º—ñ—Ä –≥—Ä–∞—Ñ—ñ–∫–∞
    """
    fig, axes = plt.subplots(2, 2, figsize=figsize)
    
    # Loss curves
    axes[0, 0].plot(train_losses, label='Train Loss', color='blue')
    axes[0, 0].plot(val_losses, label='Val Loss', color='red')
    axes[0, 0].set_title('Loss Curves')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].legend()
    axes[0, 0].grid(True)
    
    # R¬≤ curves
    train_r2 = [m['R2'] for m in train_metrics]
    val_r2 = [m['R2'] for m in val_metrics]
    axes[0, 1].plot(train_r2, label='Train R¬≤', color='blue')
    axes[0, 1].plot(val_r2, label='Val R¬≤', color='red')
    axes[0, 1].set_title('R¬≤ Curves')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('R¬≤')
    axes[0, 1].legend()
    axes[0, 1].grid(True)
    
    # RMSE curves
    train_rmse = [m['RMSE'] for m in train_metrics]
    val_rmse = [m['RMSE'] for m in val_metrics]
    axes[1, 0].plot(train_rmse, label='Train RMSE', color='blue')
    axes[1, 0].plot(val_rmse, label='Val RMSE', color='red')
    axes[1, 0].set_title('RMSE Curves')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('RMSE')
    axes[1, 0].legend()
    axes[1, 0].grid(True)
    
    # Parameter-specific R¬≤
    param_names = ['B0', 'dB', 'p', 'I']
    for i, param in enumerate(param_names):
        train_param_r2 = [m['param_metrics'][param]['R2'] for m in train_metrics]
        val_param_r2 = [m['param_metrics'][param]['R2'] for m in val_metrics]
        axes[1, 1].plot(train_param_r2, label=f'Train {param}', alpha=0.7)
        axes[1, 1].plot(val_param_r2, label=f'Val {param}', linestyle='--', alpha=0.7)
    
    axes[1, 1].set_title('Parameter-specific R¬≤')
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('R¬≤')
    axes[1, 1].legend()
    axes[1, 1].grid(True)
    
    plt.tight_layout()
    plt.show()

def save_scaler(scaler, filename):
    """
    –ó–±–µ—Ä—ñ–≥–∞—î scaler —É —Ñ–∞–π–ª
    
    Args:
        scaler: scaler –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
        filename: –Ω–∞–∑–≤–∞ —Ñ–∞–π–ª—É
    """
    with open(filename, 'wb') as f:
        pickle.dump(scaler, f)
    print(f"üíæ Scaler –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {filename}")

def load_scaler(filename):
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î scaler –∑ —Ñ–∞–π–ª—É
    
    Args:
        filename: –Ω–∞–∑–≤–∞ —Ñ–∞–π–ª—É
    
    Returns:
        scaler: –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏–π scaler
    """
    with open(filename, 'rb') as f:
        scaler = pickle.load(f)
    print(f"üìÇ Scaler –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {filename}")
    return scaler

def create_prediction_report(predictions, targets, param_names=['B0', 'dB', 'p', 'I']):
    """
    –°—Ç–≤–æ—Ä—é—î –¥–µ—Ç–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç –ø—Ä–æ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
    
    Args:
        predictions: –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
        targets: —Å–ø—Ä–∞–≤–∂–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        param_names: –Ω–∞–∑–≤–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    
    Returns:
        dict: –∑–≤—ñ—Ç –∑ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    metrics = calculate_detailed_metrics(predictions, targets, param_names)
    
    print("üìä –î–ï–¢–ê–õ–¨–ù–ò–ô –ó–í–Ü–¢ –ü–†–û –ü–ï–†–ï–î–ë–ê–ß–ï–ù–ù–Ø")
    print("=" * 50)
    
    # –ó–∞–≥–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏
    print("\nüéØ –ó–ê–ì–ê–õ–¨–ù–Ü –ú–ï–¢–†–ò–ö–ò:")
    overall = metrics['overall']
    print(f"   MSE: {overall['MSE']:.6f}")
    print(f"   RMSE: {overall['RMSE']:.6f}")
    print(f"   MAE: {overall['MAE']:.6f}")
    print(f"   R¬≤: {overall['R2']:.4f}")
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
    print("\nüìà –ú–ï–¢–†–ò–ö–ò –ü–û –ü–ê–†–ê–ú–ï–¢–†–ê–•:")
    for param in param_names:
        param_metrics = metrics[param]
        print(f"\n   {param}:")
        print(f"     R¬≤: {param_metrics['R2']:.4f}")
        print(f"     RMSE: {param_metrics['RMSE']:.6f}")
        print(f"     MAE: {param_metrics['MAE']:.6f}")
        print(f"     MSE: {param_metrics['MSE']:.6f}")
        print(f"     Mean: {param_metrics['Mean']:.4f}")
        print(f"     Std: {param_metrics['Std']:.4f}")
        print(f"     Min: {param_metrics['Min']:.4f}")
        print(f"     Max: {param_metrics['Max']:.4f}")
    
    return metrics

def plot_correlation_matrix(predictions, targets, param_names=['B0', 'dB', 'p', 'I']):
    """
    –í—ñ–∑—É–∞–ª—ñ–∑—É—î –º–∞—Ç—Ä–∏—Ü—é –∫–æ—Ä–µ–ª—è—Ü—ñ—ó –º—ñ–∂ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è–º–∏ —Ç–∞ —Å–ø—Ä–∞–≤–∂–Ω—ñ–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏
    
    Args:
        predictions: –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
        targets: —Å–ø—Ä–∞–≤–∂–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        param_names: –Ω–∞–∑–≤–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    """
    # –°—Ç–≤–æ—Ä—é—î–º–æ DataFrame
    data = {}
    for i, param in enumerate(param_names):
        data[f'True_{param}'] = targets[:, i]
        data[f'Pred_{param}'] = predictions[:, i]
    
    df = pd.DataFrame(data)
    
    # –û–±—á–∏—Å–ª—é—î–º–æ –∫–æ—Ä–µ–ª—è—Ü—ñ–π–Ω—É –º–∞—Ç—Ä–∏—Ü—é
    corr_matrix = df.corr()
    
    # –í—ñ–∑—É–∞–ª—ñ–∑—É—î–º–æ
    plt.figure(figsize=(12, 10))
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, 
                square=True, linewidths=0.5)
    plt.title('Correlation Matrix: Predictions vs True Values')
    plt.tight_layout()
    plt.show()

def save_training_results(history, filename):
    """
    –ó–±–µ—Ä—ñ–≥–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è
    
    Args:
        history: —ñ—Å—Ç–æ—Ä—ñ—è –Ω–∞–≤—á–∞–Ω–Ω—è
        filename: –Ω–∞–∑–≤–∞ —Ñ–∞–π–ª—É
    """
    with open(filename, 'wb') as f:
        pickle.dump(history, f)
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {filename}")

def load_training_results(filename):
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è
    
    Args:
        filename: –Ω–∞–∑–≤–∞ —Ñ–∞–π–ª—É
    
    Returns:
        history: —ñ—Å—Ç–æ—Ä—ñ—è –Ω–∞–≤—á–∞–Ω–Ω—è
    """
    with open(filename, 'rb') as f:
        history = pickle.load(f)
    print(f"üìÇ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {filename}")
    return history

def print_model_summary(model):
    """
    –í–∏–≤–æ–¥–∏—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å –º–æ–¥–µ–ª—ñ
    
    Args:
        model: PyTorch –º–æ–¥–µ–ª—å
    """
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print("üß† –û–ü–ò–° –ú–û–î–ï–õ–Ü:")
    print(f"   –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤: {total_params:,}")
    print(f"   –ù–∞–≤—á–∞—î–º—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏: {trainable_params:,}")
    print(f"   –†–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª—ñ: {total_params * 4 / 1024 / 1024:.2f} MB")

def check_device_availability():
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î –¥–æ—Å—Ç—É–ø–Ω—ñ—Å—Ç—å GPU
    
    Returns:
        str: –¥–æ—Å—Ç—É–ø–Ω–∏–π –ø—Ä–∏—Å—Ç—Ä—ñ–π
    """
    if torch.cuda.is_available():
        device = 'cuda'
        print(f"‚úÖ GPU –¥–æ—Å—Ç—É–ø–Ω–∏–π: {torch.cuda.get_device_name()}")
    else:
        device = 'cpu'
        print("‚ö†Ô∏è  GPU –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è CPU")
    
    return device 